# Wrangling with Webpack - pt.2 - On the Subject of Memory

*Working Draft*

**Link to Article 1**

## Introduction

This is the second half of a two-part series on how we use Webpack here at Clio. Last time, I talked briefly about the problems we faced running Webpack on our CI provider before transitioning over to discussing our upgrade path to Webpack v4. The narrative then ended on a bit of a cliff-hanger as I noted that the upgrade did not immediately solve our problems, so I would like to amend that in this article. Welcome to Wrangling with Webpack 2 - :zap: Electric Boogaloo :zap:.

## Can You Repeat the Problem?

To set the stage, I would like to begin this article by reiterating the issue that was introduced in the last article.

We use Buildkite as our CI provider, and AWS EC2 instances to actually run our CI processes. When a developer pushes a new commit up to our Github repo, Buildkite is notified via webhooks and will create a new build for this commit in each of our CI pipelines.

We have multiple pipelines for doing all sorts of stuff, but the focus of this article is on the compile pipeline, which is used to automatically compile our front-end assets. When Buildkite creates a build, it will allocate an AWS EC2 instance and install an "agent" on this machine. The agent is basically a script that will begin running the processes defined in the pipeline on the machine it was installed on:

1. It clones the Github repo and checks out the commit that triggered the build
2. It performs a number of preparatory tasks such as installing Node modules
3. It compiles all of the assets in the Rails asset pipeline (mainly used for our legacy application)
4. It compiles our revamped application, Apollo, using Webpack

This pipeline worked great, until it didn't. Our AWS EC2 instances are of type `c5.large` and have 4gb of memory. Because of other processes that run concurrently with Webpack during compilation, our Production Engineering team has explained to us that we need to ensure Webpack take no more than 2gb of memory at any given time during the build. When Webpack start to exceed this limit, we begin to experience transient build failures in the compile pipeline.

Now that the problem has been clearly identified, let's talk about the ways we tried to deal with it.

## The Blackbox Approach

We began with what could rightfully be considered a "blackbox" approach. In this approach, we treated our Webpack project as a "black box" that can only be examined and controlled from the outside.

No matter how complex your Webpack project may be, Webpack is still just a Node program that must conform to all of the normal rules that apply to any other Node program.

This means two things. First, when Webpack is running, you should be able to examine it using the `ps` utility. Second, because it is a Node program, you should be able to configure the Node process that runs it using standard CLI options, such as `--max-old-space-size`.

Let me show you how we used these tools.

To begin our analysis, we took the command that we use to compile Apollo on CI:
```
NODE_ENV=production webpack --progress --config ./config/webpack/production.js
```

And stuck it into our `package.json`:
```JSON
{
  "scripts": {
    "build:webpack": "NODE_ENV=production webpack --progress --config ./config/webpack/production.js"    
  }
}
```

This allowed us run our Webpack compilation by simply typing `yarn build:webpack`.

With Webpack running, we opened up another terminal window and executed:
```
ps ufaxww
```

`ps` is a Unix utility for printing out a snapshot of all active processes. By passing `ufaxww`, the output will show you the details of all active processes and also group together parent-child processes.

For example, here is the output we saw when we ran this command, truncated to focus on Webpack-related processes:

```sh
vagrant   3617  0.8  1.0 1138236 64720 pts/0   Sl+  17:45   0:00  node /usr/local/bin/yarn build:webpack
vagrant   3627  0.0  0.0   4300   772 pts/0    S+   17:45   0:00   \_ /bin/sh -c NODE_ENV=production node ./node_modules/webpack/bin/webpack.js --progress --config ./config/webpack/production.js
vagrant   3628 68.7  9.7 1700668 599088 pts/0  Rl+  17:45   0:29       \_ node ./node_modules/webpack/bin/webpack.js --progress --config ./config/webpack/production.js
vagrant   3634 27.5  5.6 1151908 345332 pts/0  Sl+  17:45   0:11           \_ /usr/local/stow/nodejs-8.9.4/bin/node /home/vagrant/clio/webpack/themis/node_modules/fork-ts-checker-webpack-plugin/lib/service.js
```

The sixth column from the left represents the amount of physical memory (in kb) being consumed by the process on that line. The first two lines are actually generated by `yarn`, which we were using to execute the `build:webpack` command. The third line is the actual Webpack process. The forth line is a parallel process spawned by a plugin called `fork-ts-checker-webpack-plugin` which we use to try and speed up our build. All in all, Webpack was consuming roughly 944mb of memory when this snapshot was taken.

Now that we had a sense of what is actually running when Webpack begins, we got rid of the extraneous output and asked for a summary statistic instead:
```
ps uax | grep webpack | awk '{s+=$6} END {print s}
```

This command will filter down the output from `ps` to only lines that contain the string "webpack". It then adds together the sixth column from each row and prints it out. In effect, running this command gave us a snapshot of how much memory Webpack was using in total. Depending on your situation, you may find it necessary to use a different filter, but for us, `grep webpack` was sufficient.

But a single snapshot is not all that useful. So we made a Node script:

```js
// profile-memory.js
var process = require("process");
var childProcess = require("child_process");

var repeating = setInterval(
  function() {
    childProcess.exec(
      "ps uax | grep webpack | awk '{s+=$6} END {print s}'",
      function(_err, stdout) {
        process.stdout.write(stdout.trim() + ",\n");
      }
    )
  },
  100
);

const webpack = childProcess.spawn("yarn", ["build:webpack"])
  .on("close", () => {
    clearInterval(repeating);
  });

webpack.stderr.on("data", (data) => {
  process.stderr.write(data);
});
```

When executed, `profile-memory.js` starts a new Webpack build. Then, as the build runs, a function is executed every 10th of a second that grabs the total memory being used and writes the result to standard output. Conveniently, the output of the script has been designed to be easily consumable by graphing applications.

We ran the script three times and uploaded the files to [plot.ly](https://plot.ly) to create this graph. :chart_with_upwards_trend:

![Webpack Memory Plot Baseline](assets/plot-baseline.png)
https://plot.ly/~XiaoChenClio/16/

As you can see, with our current configuration, Webpack finishes compilation in around 120 ~ 130s. At the very most, our Webpack compilation appears to use about 2 million kilobytes (2gb) of memory.

Now that we had an idea of what our Webpack build costs, what could we do? Well, this is where some knowledge about Node came in handy. Node uses V8 and can accept a number of command line options that configure the way V8 behaves. One of these is `--max-old-space-size`. To summarize Irina's [post](https://medium.com/@_lrlna/garbage-collection-in-v8-an-illustrated-guide-d24a952ee3b8), V8's memory management strategy divides up the heap into two parts: old space and new space. Objects in the old space are not subject to the frequent scavenging that occurs in the new space and are only garbage-collected when its capacity is reached. Therefore, if you set a lower capacity on the old space than the V8 default, it should lead to more garbage collections, albeit at the cost of total runtime. `--max-old-space-size` accepts a single number, interpreted as the maximum size of the old space in megabytes.

So, with this knowledge, we changed our `build:webpack` command so that we can control the size of the old space:

```
"build:webpack": "NODE_ENV=production node --max-old-space-size=SIZE ./node_modules/webpack/bin/webpack.js --progress --config ./config/webpack/production.js",
```

We tried three different values for `SIZE`: 1024, 896 and 768. Our project compiled successfully at both 1024 and 896, but failed at 768. Using `profile-memory.js`, the results of the two successful trials were logged. We created a graph to compare the results:

![Webpack Memory Plot Old Space](assets/plot-old-space.png)
https://plot.ly/~XiaoChenClio/1/

As we reduced the maximum size of the old space, Webpack took longer to build our project, but the amount of memory it consumed also decreased. We found `--max-old-space-size=1024` to be a sweet spot, as it reduced the the maximum memory used by around 400mb, at the acceptable cost of +10s in total compile time.

It is also worth noting `--max-old-space-size` will have no effect on parallel processes spawned during compilation, such as `fork-ts-checker`. It only affects the immediate Node process it is passed to.

### Key takeaways

TODO Make this flow more

1. Good tooling is essential to solving any problem. Without it, you can't properly diagnose a problem nor can you validate different hypotheses
2. Node let's you control the size of V8's old space; setting it to a lower value can help reduce the amount of memory Webpack takes to compile your project, at the cost of longer compile times.

Admittedly, the effectiveness of the methods described in blackbox approach is limited:

1. While `profile-memory.js` gives you a good high-level overview of your Webpack project, it does not tell you exactly where the memory usage is coming from
2. While limiting old max space size may help reduce memory usage, it comes at the cost of longer runtimes and also have to be adjusted and increased over time as your project grows

Not satisfied with the blackbox approach? Well, neither were we. To make a medical analogy, if our Webpack memory issue was a sickness, then the blackbox approach has just told us exactly what our symptoms are and what a painkiller might be. But the true cause of our sickness is yet unknown. For that, we will need something more powerful.

## The Whitebox Approach

Following the blackbox approach, we put on our safari hats and delve deep into our Webpack project. Our plan was, plain and simple, to identify the cause of Webpack's voracious demand for memory. In an ideal world, we would have identified a single issue, perhaps an non-optimized plugin, that both used a lot of memory and for which a straight-forward solution exists. However, if this were the case, I would have told you about it by now.

The reality, as you can tell, didn't turn out so neatly. As opposed to finding that one silver bullet solution, the whitebox approach instead gave us:

* **Three** strategies for identifying memory bottlenecks
* **Two** domain-specific solutions for reducing memory usage
* **One** surprising discovery about our Webpack build

And it is these things that I would like to now share with you.

### Key takeaways

* Identify and profile memory consumers in your Webpack set-up. Know what pieces incur the heaviest cost and prioritize optimization efforts accordingly.
* If the time trade-off is acceptable, reduce the number of processes that are running parallel on the same machine
* Scale horizontally (Across multiple machines) if possible

### Three Strategies

Continuing with the safari analogy, you might think of these strategies as the "tracks" we followed in our hunt. Not all of them led to solutions, but each approached the memory issue from a different angle and, as a result, deserves to be mentioned here.

In our first strategy, we examined the way we configured Webpack. Generally speaking, a Webpack project is configurable in three different ways: by adjusting Webpack's native options, by adding custom plugins, and by adding custom loaders. In our case, since we did not see anything suspicious with our native options, we focused on our plugins and loaders instead.

Beginning with the plugins we used in our production environment, we disabled each of them individually (Most of the time, this was as simple as just commenting it out of our `plugins` array) and ran `profile-memory.js` to get an idea of how much memory overhead it added during compilation.

For example, one of the plugins we were using was the [ForkTsCheckerWebpackPlugin](github.com/Realytics/fork-ts-checker-webpack-plugin), which helped speed up our Webpack compilation by creating a separate process to perform all TypeScript typechecking. We disabled it and ran `profile-memory.js`. The results were then recorded:

![Webpack Memory No Fork](assets/plot-fork-ts.png)
https://plot.ly/~XiaoChenClio/12

As surprising as this result was, it was also somewhat of a red herring. Without ForkTsChecker, we not only saw maximum memory usage decrease by around 200mb, but also a reduction of the total compile time by around 20s. However, This was purely due to the fact that, without ForkTsChecker and without turning back on typeschecking in ts-loader, Webpack was no longer performing any form of typechecking during compilation. Of course, we couldn't just forgo typechecking all-together, but this discovery did give us an idea that will be elaborated on shortly.

For the record, we also found [SourceMapDevToolPlugin](https://webpack.js.org/plugins/source-map-dev-tool-plugin/) and [UglifyjsWebpackPlugin](https://webpack.js.org/plugins/uglifyjs-webpack-plugin/) to be heavy consumers of memory as well. But we couldn't find a good way to use this information.

We then applied this process of "isolate-and-compile" to our loaders. We did this by using the [IgnoreLoader](https://github.com/cherrry/ignore-loader). So, for example, to measure the impact of the loaders we were using for CoffeeScript files, we would update our configuration like so:

```js
// webpack configuration snippet
module.exports = {
  // ... Other configuration
  module: {
    rules: [
      {
        test: /\.coffee(\.erb)?$/,
        // loader: 'ng-annotate-loader!coffee-loader' // Comment out the actual loaders
        loader: 'ignore-loader', // Tell Webpack to ignore all CoffeeScript files
      },
      // ... other rules
    ],
  },
}
```

The results of these tests, however, were not as useful as the plugins beforehand. We found that the loaders that incurred the heaviest memory tax were our TypeScript, CoffeeScript, and Sass loaders, but this was largely due to fact that these were the most common types of files in our project. We couldn't really replace these loaders: doing so would most likely achieve little, and it puts us at risk of breaking our app. So, the information, as interesting as it were, gave us little to actually work with.

So let's talk about the second strategy, which focuses instead on the actual bundles that Webpack generates. Here, we started by using the [Webpack Bundle Analyzer](https://github.com/webpack-contrib/webpack-bundle-analyzer) to visualize the shapes and sizes of our final, compiled bundles.

The graph that we received from the Analyzer was very telling:

![Bundles analyzed](assets/bundles-analyzed.png)

The majority of our bundled JavaScript assets, as it turned out, came from our `node_modules` folder! What's more, within the code from `node_modules`, the largest part was by far from `lib-ThemisUI`. `lib-ThemisUI` is an internal components library that we have created for our web app. It is not a complex components library, and really should not take up such a large part of our bundled assets.

Now that we had a suspect on our hands, we wanted to see what would happen to our compilation if we were to take `lib-ThemisUI` out of the equation. To do this, we used Webpack's [IgnorePlugin](https://webpack.js.org/plugins/ignore-plugin/) to ignore all attempts to include code from `lib-ThemisUI`:

```js
// webpack configuration snippet
module.exports = {
  // ... Other configuration
  plugins: [
    new webpack.IgnorePlugin(/lib-ThemisUI/),
    // ... other plugins
  ],
}
```

With `lib-ThemisUI` out of the picture, we profiled our compilation again and recorded the results (If you are wondering why the compile times are faster, it's because these tests were ran on a slightly faster machine than the other tests):

![No ThemisUI](assets/plot-no-themisui.png)
https://plot.ly/~XiaoChenClio/28/

In terms of memory, we saw the maximum memory used by Webpack decrease by around 150mb. The runtime difference is also worth noting: without `lib-ThemisUI`, total compilation time decreased by around 15s. On the surface, these results may not seem significant, that is until you consider the fact that `lib-ThemisUI` should be a simple, run-of-the-mill component library.

The reason why `lib-ThemisUI` taxes us this heavily is because it is a *huge* import: As you can see, the curves of the two compilations are almost identical up until around x=750. This, incidentally, is when the things like uglification and source-map generation begins. Because `lib-ThemisUI` is being included, it too has to undergo this process. The sheer size of the import leads directly to greater consumption of memory and a longer compile time.

Being a component library that merely defines a number of simple UI components like buttons and drop-down menus, we felt that the complexity of `lib-ThemisUI` did not justify its size. So, now that we identified this problem, what did we do? Well, nothing. I mean, we couldn't really do anything immediately. This issue requires us to look into our component library in greater detail and to identify exactly what is making it so large. We looked around for flagrant fouls, but didn't find any. Thus, we put it aside on our TODO list, and proceeded to our final strategy of investigation.

### Using the Node Inspector
